{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fMS9K4N7ahpS",
        "2n2vi3qEcpVC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling with Gensim\n",
        "\n",
        "*Notebook version: 1.2402.0701*\n",
        "\n",
        "Weâ€™re going to use the gensim implementations because they offer more functionality out of the box"
      ],
      "metadata": {
        "id": "EKD97tPrdytR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "pLwZeINieF7r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa6NCL0xP1Sf"
      },
      "outputs": [],
      "source": [
        "!pip install sastrawi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import re\n",
        "\n",
        "from gensim import models, corpora\n",
        "from gensim.parsing.preprocessing import preprocess_string\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "NlW34vxmQGDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "jiOvWtosgCRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function"
      ],
      "metadata": {
        "id": "zo-7tpzaey9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_clean(text):\n",
        "  return preprocess_string(text)"
      ],
      "metadata": {
        "id": "xMHWiPWhSAn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('indonesian')\n",
        "def remove_stopwords(tokenized_text):\n",
        "\n",
        "    cleaned_token = []\n",
        "    for token in tokenized_text:\n",
        "        if token not in stopwords:\n",
        "            cleaned_token.append(token)\n",
        "\n",
        "    return cleaned_token"
      ],
      "metadata": {
        "id": "8KCCQnP8S3GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming_text(tokenized_text):\n",
        "\n",
        "    #stem using Sastrawi StemmerFactory\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    stems = []\n",
        "    for token in tokenized_text:\n",
        "        stems.append(stemmer.stem(token))\n",
        "\n",
        "    return stems"
      ],
      "metadata": {
        "id": "spe5ilAbTMKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "\n",
        "    prep01 = tokenize_clean(text)\n",
        "    prep02 = remove_stopwords(prep01)\n",
        "    prep03 = stemming_text(prep02)\n",
        "\n",
        "    return prep03"
      ],
      "metadata": {
        "id": "5pf3ijLmTOB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "BF943Gr3gBFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Dataset"
      ],
      "metadata": {
        "id": "fn0smxjDe_9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p dataset\n",
        "!wget https://raw.githubusercontent.com/project303/dataset/master/Berita.txt -P dataset\n",
        "!wget https://raw.githubusercontent.com/project303/dataset/master/Judul-Berita.txt -P dataset"
      ],
      "metadata": {
        "id": "4t6hG804QViy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read article title\n",
        "article_titles = open('dataset/Judul-Berita.txt').read().split('\\n')\n",
        "len(article_titles)"
      ],
      "metadata": {
        "id": "wTTgRko1ZNRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read article content\n",
        "article = open('dataset/Berita.txt', encoding=\"utf8\").read().split('BERHENTI DISINI')\n",
        "len(article)"
      ],
      "metadata": {
        "id": "4bkN_7l2QbZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article[0]"
      ],
      "metadata": {
        "id": "Asr6bNjDQfsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "IZftfrgwfNOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove HTML tag\n",
        "article_clean = []\n",
        "for text in article:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    article_clean.append(text)\n",
        "article = article_clean"
      ],
      "metadata": {
        "id": "yRQKqOomQnbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article[0]"
      ],
      "metadata": {
        "id": "JFAUKRfaRMkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(article[0])"
      ],
      "metadata": {
        "id": "aY-0D1VzQsrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# proses ini memerlukan waktu sekitar 3 menit\n",
        "tokenized_data = []\n",
        "for text in article:\n",
        "    tokenized_data.append(text_preprocessing(text))"
      ],
      "metadata": {
        "id": "lRFmaXS9RnOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_data)"
      ],
      "metadata": {
        "id": "xhtnyUk4Rs5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_data[0])"
      ],
      "metadata": {
        "id": "T4gdofb_Rwzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_data[0])"
      ],
      "metadata": {
        "id": "wZ0Ldru5R-OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "CIY2zagDf_ZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create The Model"
      ],
      "metadata": {
        "id": "-PyJN4S6fXXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Dictionary - association word to numeric id\n",
        "dictionary = corpora.Dictionary(tokenized_data)\n",
        "\n",
        "# Transform the collection of texts to a numerical form\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_data]"
      ],
      "metadata": {
        "id": "fWkjcMENX68U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TOPICS = 3\n",
        "\n",
        "# Build the LDA model\n",
        "lda_model = models.LdaModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary, alpha = 'auto', eval_every=5)#, per_word_topics=True)\n",
        "\n",
        "# Build the LSI model\n",
        "lsi_model = models.LsiModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)"
      ],
      "metadata": {
        "id": "-0-_HUgAYCQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LDA Model:\")\n",
        "\n",
        "for idx in range(NUM_TOPICS):\n",
        "    # Print the first 10 most representative topics\n",
        "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 10))\n",
        "\n",
        "print(\"=\" * 20)\n",
        "\n",
        "print(\"LSI Model:\")\n",
        "\n",
        "for idx in range(NUM_TOPICS):\n",
        "    # Print the first 10 most representative topics\n",
        "    print(\"Topic #%s:\" % idx, lsi_model.print_topic(idx, 10))\n",
        "\n",
        "print(\"=\" * 20)"
      ],
      "metadata": {
        "id": "Pow8aM2gYOvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFQqoZ-EYRQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "F6WuayWQf9xJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test The Model"
      ],
      "metadata": {
        "id": "poLi6xrefdOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"article[0]\")\n",
        "print(\"LDA Model:\")\n",
        "print(lda_model[corpus[0]])\n",
        "\n",
        "print(\"\")\n",
        "print(\"LSA Model:\")\n",
        "print(lsi_model[corpus[0]])"
      ],
      "metadata": {
        "id": "pshlWvocYWXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_data[0])"
      ],
      "metadata": {
        "id": "69ktXWTuYrTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_titles[0]"
      ],
      "metadata": {
        "id": "u4vP1NzIZQ-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Pertandingan berjalan dengan seru. Tim lawan berhasil dikalahkan dengan skor 1-0.\"\n",
        "bow = dictionary.doc2bow(text_preprocessing(text))\n",
        "\n",
        "print(\"LDA Model:\")\n",
        "print(lda_model[bow])\n",
        "print(\"\")\n",
        "print(\"LSA Model:\")\n",
        "print(lsi_model[bow])\n",
        "\n",
        "#print(bow)"
      ],
      "metadata": {
        "id": "tSJQyKo_ZRzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dictionary)"
      ],
      "metadata": {
        "id": "K-_lHXsCaeS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BV-KyEaag1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import similarities\n",
        "\n",
        "lda_index = similarities.MatrixSimilarity(lda_model[corpus])\n",
        "\n",
        "# Let's perform some queries\n",
        "similarities = lda_index[lda_model[bow]]\n",
        "# Sort the similarities\n",
        "similarities = sorted(enumerate(similarities), key=lambda item: -item[1])\n",
        "\n",
        "# Top most similar documents:\n",
        "print(similarities[:10])\n",
        "\n",
        "# Let's see what's the most similar document\n",
        "document_id, similarity = similarities[0]\n",
        "print(article[document_id][:1000])"
      ],
      "metadata": {
        "id": "lwDkDmPSc9dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "TbIt-VAxf79c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "WyhHd4VFfi0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyLDAVis (specific version for Google Collab)\n",
        "#!pip install pyLDAvis==2.1.2\n",
        "#!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "8sctNJ6jdY75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "panel"
      ],
      "metadata": {
        "id": "2bvsdXTSdF-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "vzjJGbEiah0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Dictionary and doc2bow Work"
      ],
      "metadata": {
        "id": "fMS9K4N7ahpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [['durian', 'belimbing', 'cempedak' ], ['apel', 'belimbing']]\n",
        "\n",
        "dct = corpora.Dictionary(texts)  # initialize a Dictionary"
      ],
      "metadata": {
        "id": "hj70fA0oal5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dct)"
      ],
      "metadata": {
        "id": "kBJJIXytcJvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dct.keys()"
      ],
      "metadata": {
        "id": "DiRiygbXcL7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dct[1]"
      ],
      "metadata": {
        "id": "XGy6FnUCcVC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dct.doc2bow([\"belimbing\", \"apel\", \"non_existent_word\"])"
      ],
      "metadata": {
        "id": "WVNE0ZFEcHfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "kDK5VuSLgK3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Revision History\n"
      ],
      "metadata": {
        "id": "2n2vi3qEcpVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Release: 1.2102.0601\n",
        "*   First release\n",
        "\n",
        "Release: 1.2402.0701\n",
        "*   Change preprocessing process\n",
        "*   Add how Dictionary dan doc2bow works"
      ],
      "metadata": {
        "id": "htqCRtcVgOrR"
      }
    }
  ]
}